{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7149d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cc0eb3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "53540c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d8e27626",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.softmax(torch.rand(3), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5692234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq = p*q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d44c3d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2752, 0.1149, 0.1412])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d222a979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6023, 0.4062, 0.5428])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "70e34fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4570, 0.2830, 0.2601])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d422fbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d3357d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4687, 0.5313])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y = p ** y.unsqueeze(dim=1) * (1 - p)** (1 - y.unsqueeze(dim=1))\n",
    "(p_y*q).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "21c3ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_y tensor([0.3977, 0.5938, 0.4572])\n",
      "p_y_under_q tensor(0.4687)\n",
      "\n",
      "p_y tensor([0.6023, 0.4062, 0.5428])\n",
      "p_y_under_q tensor(0.5313)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for y_ in torch.arange(2):\n",
    "    p_y = p ** y_ * (1 - p) ** (1 - y_)\n",
    "    print(\"p_y\", p_y)\n",
    "    p_y_under_q = (p_y * q).sum()\n",
    "    print(\"p_y_under_q\", p_y_under_q)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ce10bdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [2, 3] but got: [2, 1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m p_y\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;129m@q\u001b[39m\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [2, 3] but got: [2, 1]."
     ]
    }
   ],
   "source": [
    "p_y.unsqueeze(dim=1).dot(q.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67f1fb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1813, 0.4704, 0.3445])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8*q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60bff5e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m p_y \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m y \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m p) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y)\n\u001b[1;32m      2\u001b[0m p_y_under_q \u001b[38;5;241m=\u001b[39m (p_y \u001b[38;5;241m*\u001b[39m q)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m p_y_under_q\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/_tensor.py:32\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "p_y = p ** y * (1 - p) ** (1 - y)\n",
    "p_y_under_q = (p_y * q).sum(axis=0)\n",
    "p_y_under_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "563d0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_targets=2\n",
    "b_prime = torch.rand(size=(n_targets, 2))\n",
    "b = torch.rand(size=(n_targets, 2))\n",
    "n_sample = 1000\n",
    "a = torch.rand(size=(n_targets,))\n",
    "y = torch.tensor([1])\n",
    "\n",
    "eps = torch.randn((n_targets, n_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0520e282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7702)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_q = 0\n",
    "log_p = 0\n",
    "\n",
    "distance_t = 0\n",
    "\n",
    "for t in range(n_targets):\n",
    "\n",
    "    mu, log_var = b_prime[t]\n",
    "    std = torch.exp(0.5 * log_var)\n",
    "\n",
    "    \n",
    "    z = eps[t] * std + mu\n",
    "\n",
    "    dist_b_prime = torch.distributions.Normal(mu, std)\n",
    "\n",
    "    log_q += dist_b_prime.log_prob(z).sum()\n",
    "\n",
    "    mu, log_var = b[t]\n",
    "    std = (0.5 * log_var).exp()\n",
    "    dist_b = torch.distributions.Normal(mu, std)\n",
    "\n",
    "    log_p += dist_b.log_prob(z).sum()\n",
    "    z_scaled = torch.sigmoid(z)\n",
    "    dist = torch.absolute(a[t] - z_scaled)\n",
    "    distance_t += dist\n",
    "\n",
    "distance_t /= n_targets\n",
    "prm = (100.0, 0.1)\n",
    "x = prm[0]*(- prm[1] + distance_t)\n",
    "p = torch.sigmoid(x)\n",
    "\n",
    "p_y = p**y * (1 - p)**(1 - y)\n",
    "log_p += (p_y+1e-8).log().sum()\n",
    "\n",
    "kl_est = (log_q - log_p) / n_sample\n",
    "kl_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275657a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_q = 0\n",
    "log_p = 0\n",
    "\n",
    "distance_t = 0\n",
    "\n",
    "for t in range(n_targets):\n",
    "\n",
    "    mu, log_var = b_prime[t]\n",
    "    std = torch.exp(0.5 * log_var)\n",
    "\n",
    "    z = eps[t] * std + mu\n",
    "\n",
    "    dist_b_prime = torch.distributions.Normal(mu, std)\n",
    "\n",
    "    log_q += dist_b_prime.log_prob(z).sum()\n",
    "\n",
    "    mu, log_var = b[t]\n",
    "    std = (0.5 * log_var).exp()\n",
    "    dist_b = torch.distributions.Normal(mu, std)\n",
    "\n",
    "    log_p += dist_b.log_prob(z).sum()\n",
    "    z_scaled = torch.sigmoid(z)\n",
    "    dist = torch.absolute(a[t] - z_scaled)\n",
    "    distance_t += dist\n",
    "\n",
    "distance_t /= n_targets\n",
    "prm = (100.0, 0.1)\n",
    "x = prm[0]*(- prm[1] + distance_t)\n",
    "p = torch.sigmoid(x)\n",
    "\n",
    "p_y = p**y * (1 - p)**(1 - y)\n",
    "log_p += (p_y+1e-8).log().sum()\n",
    "\n",
    "kl_est = (log_q - log_p) / n_sample\n",
    "kl_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bef94617",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_targets = 2\n",
    "prm = (10.0, 0.1)\n",
    "\n",
    "b_prime = torch.rand(size=(n_targets, 2))\n",
    "b = torch.rand(size=(n_targets, 2))\n",
    "a = torch.rand(size=(n_targets,))\n",
    "y = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "345a1b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu tensor(0.6251)\n",
      "z mean tensor(0.6256)\n",
      "dist tensor(1.2869)\n",
      "mu tensor(0.9090)\n",
      "z mean tensor(0.9092)\n",
      "dist tensor(1.2776)\n",
      "distance_t tensor(2.5645)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sample = int(10e6)\n",
    "eps = torch.randn((n_targets, n_sample))\n",
    "\n",
    "log_p = 0\n",
    "distance_t = 0\n",
    "\n",
    "for t in range(n_targets):\n",
    "\n",
    "    mu, log_var = b_prime[t]\n",
    "    std = (0.5 * log_var).exp()\n",
    "\n",
    "    z = eps[t] * std + mu\n",
    "    print(\"mu\", mu)\n",
    "    print(\"z mean\", z.mean())\n",
    "\n",
    "    z_scaled = z # torch.sigmoid(z)\n",
    "    dist = torch.absolute(a[t] - z_scaled)\n",
    "    print(\"dist\", dist.mean())\n",
    "    distance_t += dist.sum()\n",
    "\n",
    "distance_t /= (n_targets + n_sample)\n",
    "print(\"distance_t\", distance_t)\n",
    "\n",
    "x = prm[0]*(- prm[1] + distance_t)\n",
    "p = torch.sigmoid(x)\n",
    "\n",
    "p_y = p**y * (1 - p)**(1 - y)\n",
    "log_p += (p_y+1e-8).log()\n",
    "\n",
    "log_p\n",
    "\n",
    "\n",
    "# dist_b_prime = torch.distributions.Normal(mu, std)\n",
    "\n",
    "#     log_q += dist_b_prime.log_prob(z).sum()\n",
    "\n",
    "#     mu, log_var = b[t]\n",
    "#     std = (0.5 * log_var).exp()\n",
    "#     dist_b = torch.distributions.Normal(mu, std)\n",
    "\n",
    "#     log_p += dist_b.log_prob(z).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d08007ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.rand(n_targets)\n",
    "log_var = torch.rand(n_targets)\n",
    "eps = torch.randn((n_sample, n_targets))\n",
    "\n",
    "std = (0.5 * log_var).exp()\n",
    "z = eps * std + mu\n",
    "z_scaled = torch.sigmoid(z)\n",
    "distance = torch.absolute(z_scaled - a)\n",
    "\n",
    "average_distance = distance.mean(axis=-1)\n",
    "\n",
    "x = prm[0]*(- prm[1] + average_distance)\n",
    "p = torch.sigmoid(x)\n",
    "logp_y = (p**y * (1 - p)**(1 - y) + 1e-8).log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "31e21d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_targets = 100\n",
    "\n",
    "mu = torch.rand(n_targets)\n",
    "log_var = torch.rand(n_targets)\n",
    "std = (0.5 * log_var).exp()\n",
    "\n",
    "prior_mu = torch.rand(n_targets)\n",
    "prior_log_var = torch.rand(n_targets)\n",
    "prior_std = (0.5 * prior_log_var).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "386e7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v1():\n",
    "    q = torch.distributions.MultivariateNormal(mu, scale_tril=torch.diag(std))\n",
    "    p = torch.distributions.MultivariateNormal(prior_mu, scale_tril=torch.diag(prior_std))\n",
    "\n",
    "    return torch.distributions.kl.kl_divergence(q, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "65efc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v2():\n",
    "    div = 0\n",
    "    for i in range(n_targets):\n",
    "        q = torch.distributions.Normal(mu[i], std[i])\n",
    "        p = torch.distributions.Normal(prior_mu[i], prior_std[i])\n",
    "\n",
    "        div += torch.distributions.kl.kl_divergence(q, p)\n",
    "\n",
    "    return div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "33eef6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 µs ± 2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "41c6cd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.53 ms ± 11.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb2e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = \n",
    "distance_t /= n_targets\n",
    "\n",
    "x = prm[0]*(- prm[1] + distance_t)\n",
    "p = torch.sigmoid(x)\n",
    "\n",
    "p_y = p**y * (1 - p)**(1 - y)\n",
    "log_p += (p_y+1e-8).log()\n",
    "\n",
    "log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5dfaa632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9090)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9094)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sample = int(10e6)\n",
    "eps = torch.randn((n_targets, n_sample))\n",
    "\n",
    "print(mu)\n",
    "(mu + std *eps).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "463a80ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(79.8457)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.absolute(torch.randn(size=(100000,))*100.00 - 0.5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7237d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_belief(b, a, y, conditional_probability_action, \n",
    "                  lr=0.1, max_n_epochs=500,\n",
    "                  n_sample=1000):\n",
    "    \n",
    "    n_targets = len(a)\n",
    "    \n",
    "    # Start by creating a new belief `b_prime` the previous belief `b`\n",
    "    b_prime = torch.nn.Parameter(b.clone())\n",
    "\n",
    "    prior_mu, prior_log_var = b.T\n",
    "    prior_std = (0.5 * prior_log_var).exp()\n",
    "\n",
    "    p_dist = torch.distributions.MultivariateNormal(prior_mu, scale_tril=torch.diag(prior_std))\n",
    "\n",
    "    opt = torch.optim.Adam([b_prime, ], lr=lr)\n",
    "\n",
    "    # Minimise free energy\n",
    "    for step in range(max_n_epochs):\n",
    "\n",
    "        old_b_prime = b_prime.clone()\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        mu, log_var = b_prime.T\n",
    "        std = (0.5 * log_var).exp()\n",
    "        eps = torch.randn((n_sample, n_targets))\n",
    "\n",
    "        z = eps * std + mu\n",
    "        z_scaled = torch.sigmoid(z)\n",
    "        \n",
    "        distance = torch.absolute(z_scaled - a)\n",
    "        average_distance = distance.mean(axis=-1)\n",
    "\n",
    "        p = conditional_probability_action(average_distance)\n",
    "        \n",
    "        accuracy = (p ** y * (1 - p) ** (1 - y) + 1e-8).log().mean()\n",
    "\n",
    "        q_dist = torch.distributions.MultivariateNormal(mu, scale_tril=torch.diag(std))\n",
    "\n",
    "        complexity = torch.distributions.kl.kl_divergence(q_dist, p_dist)\n",
    "        # torch.autograd.set_detect_anomaly(True)\n",
    "        loss = - accuracy + complexity\n",
    "        print(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if torch.isclose(old_b_prime, b_prime).all():\n",
    "            print(f\"converged at step {step}\")\n",
    "            break\n",
    "\n",
    "    return b_prime.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "69710505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.4156, grad_fn=<AddBackward0>)\n",
      "tensor(18.3643, grad_fn=<AddBackward0>)\n",
      "tensor(18.2869, grad_fn=<AddBackward0>)\n",
      "tensor(18.3374, grad_fn=<AddBackward0>)\n",
      "tensor(18.3791, grad_fn=<AddBackward0>)\n",
      "tensor(18.2886, grad_fn=<AddBackward0>)\n",
      "tensor(18.2812, grad_fn=<AddBackward0>)\n",
      "tensor(18.2645, grad_fn=<AddBackward0>)\n",
      "tensor(18.2440, grad_fn=<AddBackward0>)\n",
      "tensor(18.4028, grad_fn=<AddBackward0>)\n",
      "tensor(17.9944, grad_fn=<AddBackward0>)\n",
      "tensor(17.9634, grad_fn=<AddBackward0>)\n",
      "tensor(17.8701, grad_fn=<AddBackward0>)\n",
      "tensor(17.9427, grad_fn=<AddBackward0>)\n",
      "tensor(17.7888, grad_fn=<AddBackward0>)\n",
      "tensor(17.7875, grad_fn=<AddBackward0>)\n",
      "tensor(17.5676, grad_fn=<AddBackward0>)\n",
      "tensor(17.3051, grad_fn=<AddBackward0>)\n",
      "tensor(17.3439, grad_fn=<AddBackward0>)\n",
      "tensor(17.7374, grad_fn=<AddBackward0>)\n",
      "tensor(17.4463, grad_fn=<AddBackward0>)\n",
      "tensor(17.3620, grad_fn=<AddBackward0>)\n",
      "tensor(17.2763, grad_fn=<AddBackward0>)\n",
      "tensor(16.8976, grad_fn=<AddBackward0>)\n",
      "tensor(17.3543, grad_fn=<AddBackward0>)\n",
      "tensor(17.0541, grad_fn=<AddBackward0>)\n",
      "tensor(17.0833, grad_fn=<AddBackward0>)\n",
      "tensor(17.1061, grad_fn=<AddBackward0>)\n",
      "tensor(16.7932, grad_fn=<AddBackward0>)\n",
      "tensor(16.8230, grad_fn=<AddBackward0>)\n",
      "tensor(16.7829, grad_fn=<AddBackward0>)\n",
      "tensor(16.7513, grad_fn=<AddBackward0>)\n",
      "tensor(16.4849, grad_fn=<AddBackward0>)\n",
      "tensor(16.9492, grad_fn=<AddBackward0>)\n",
      "tensor(16.4092, grad_fn=<AddBackward0>)\n",
      "tensor(16.3297, grad_fn=<AddBackward0>)\n",
      "tensor(16.5894, grad_fn=<AddBackward0>)\n",
      "tensor(16.5924, grad_fn=<AddBackward0>)\n",
      "tensor(16.5489, grad_fn=<AddBackward0>)\n",
      "tensor(15.9536, grad_fn=<AddBackward0>)\n",
      "tensor(16.5168, grad_fn=<AddBackward0>)\n",
      "tensor(16.3456, grad_fn=<AddBackward0>)\n",
      "tensor(16.1535, grad_fn=<AddBackward0>)\n",
      "tensor(16.2909, grad_fn=<AddBackward0>)\n",
      "tensor(16.1323, grad_fn=<AddBackward0>)\n",
      "tensor(16.2447, grad_fn=<AddBackward0>)\n",
      "tensor(15.9749, grad_fn=<AddBackward0>)\n",
      "tensor(15.8029, grad_fn=<AddBackward0>)\n",
      "tensor(15.9971, grad_fn=<AddBackward0>)\n",
      "tensor(15.6901, grad_fn=<AddBackward0>)\n",
      "tensor(15.8946, grad_fn=<AddBackward0>)\n",
      "tensor(15.5357, grad_fn=<AddBackward0>)\n",
      "tensor(15.5238, grad_fn=<AddBackward0>)\n",
      "tensor(15.2081, grad_fn=<AddBackward0>)\n",
      "tensor(14.7726, grad_fn=<AddBackward0>)\n",
      "tensor(14.6470, grad_fn=<AddBackward0>)\n",
      "tensor(14.1978, grad_fn=<AddBackward0>)\n",
      "tensor(13.8129, grad_fn=<AddBackward0>)\n",
      "tensor(13.0306, grad_fn=<AddBackward0>)\n",
      "tensor(12.6880, grad_fn=<AddBackward0>)\n",
      "tensor(12.1558, grad_fn=<AddBackward0>)\n",
      "tensor(11.9832, grad_fn=<AddBackward0>)\n",
      "tensor(11.4957, grad_fn=<AddBackward0>)\n",
      "tensor(10.9768, grad_fn=<AddBackward0>)\n",
      "tensor(10.5077, grad_fn=<AddBackward0>)\n",
      "tensor(10.1727, grad_fn=<AddBackward0>)\n",
      "tensor(10.1422, grad_fn=<AddBackward0>)\n",
      "tensor(9.8974, grad_fn=<AddBackward0>)\n",
      "tensor(9.6892, grad_fn=<AddBackward0>)\n",
      "tensor(9.1612, grad_fn=<AddBackward0>)\n",
      "tensor(8.8634, grad_fn=<AddBackward0>)\n",
      "tensor(8.4847, grad_fn=<AddBackward0>)\n",
      "tensor(8.2728, grad_fn=<AddBackward0>)\n",
      "tensor(8.0454, grad_fn=<AddBackward0>)\n",
      "tensor(8.1276, grad_fn=<AddBackward0>)\n",
      "tensor(8.1280, grad_fn=<AddBackward0>)\n",
      "tensor(8.1026, grad_fn=<AddBackward0>)\n",
      "tensor(7.9603, grad_fn=<AddBackward0>)\n",
      "tensor(8.0227, grad_fn=<AddBackward0>)\n",
      "tensor(7.8277, grad_fn=<AddBackward0>)\n",
      "tensor(7.8251, grad_fn=<AddBackward0>)\n",
      "tensor(7.8185, grad_fn=<AddBackward0>)\n",
      "tensor(7.8449, grad_fn=<AddBackward0>)\n",
      "tensor(7.8301, grad_fn=<AddBackward0>)\n",
      "tensor(7.8895, grad_fn=<AddBackward0>)\n",
      "tensor(7.8984, grad_fn=<AddBackward0>)\n",
      "tensor(7.8692, grad_fn=<AddBackward0>)\n",
      "tensor(7.8927, grad_fn=<AddBackward0>)\n",
      "tensor(7.8177, grad_fn=<AddBackward0>)\n",
      "tensor(7.8056, grad_fn=<AddBackward0>)\n",
      "tensor(7.8311, grad_fn=<AddBackward0>)\n",
      "tensor(7.8237, grad_fn=<AddBackward0>)\n",
      "tensor(7.8713, grad_fn=<AddBackward0>)\n",
      "tensor(7.8505, grad_fn=<AddBackward0>)\n",
      "tensor(7.8696, grad_fn=<AddBackward0>)\n",
      "tensor(7.8435, grad_fn=<AddBackward0>)\n",
      "tensor(7.8487, grad_fn=<AddBackward0>)\n",
      "tensor(7.8369, grad_fn=<AddBackward0>)\n",
      "tensor(7.8626, grad_fn=<AddBackward0>)\n",
      "tensor(7.8706, grad_fn=<AddBackward0>)\n",
      "tensor(7.8762, grad_fn=<AddBackward0>)\n",
      "tensor(7.8463, grad_fn=<AddBackward0>)\n",
      "tensor(7.8676, grad_fn=<AddBackward0>)\n",
      "tensor(7.8489, grad_fn=<AddBackward0>)\n",
      "tensor(7.8106, grad_fn=<AddBackward0>)\n",
      "tensor(7.8499, grad_fn=<AddBackward0>)\n",
      "tensor(7.8189, grad_fn=<AddBackward0>)\n",
      "tensor(7.8574, grad_fn=<AddBackward0>)\n",
      "tensor(7.8489, grad_fn=<AddBackward0>)\n",
      "tensor(7.8444, grad_fn=<AddBackward0>)\n",
      "tensor(7.8774, grad_fn=<AddBackward0>)\n",
      "tensor(7.8393, grad_fn=<AddBackward0>)\n",
      "tensor(7.8066, grad_fn=<AddBackward0>)\n",
      "tensor(7.8487, grad_fn=<AddBackward0>)\n",
      "tensor(7.7784, grad_fn=<AddBackward0>)\n",
      "tensor(7.8459, grad_fn=<AddBackward0>)\n",
      "tensor(7.8021, grad_fn=<AddBackward0>)\n",
      "tensor(7.8017, grad_fn=<AddBackward0>)\n",
      "tensor(7.8214, grad_fn=<AddBackward0>)\n",
      "tensor(7.8625, grad_fn=<AddBackward0>)\n",
      "tensor(7.8358, grad_fn=<AddBackward0>)\n",
      "tensor(7.8012, grad_fn=<AddBackward0>)\n",
      "tensor(7.8808, grad_fn=<AddBackward0>)\n",
      "tensor(7.8229, grad_fn=<AddBackward0>)\n",
      "tensor(7.8279, grad_fn=<AddBackward0>)\n",
      "tensor(7.8094, grad_fn=<AddBackward0>)\n",
      "tensor(7.9039, grad_fn=<AddBackward0>)\n",
      "tensor(7.8278, grad_fn=<AddBackward0>)\n",
      "tensor(7.8597, grad_fn=<AddBackward0>)\n",
      "tensor(7.8393, grad_fn=<AddBackward0>)\n",
      "tensor(7.8286, grad_fn=<AddBackward0>)\n",
      "tensor(7.8290, grad_fn=<AddBackward0>)\n",
      "tensor(7.8132, grad_fn=<AddBackward0>)\n",
      "tensor(7.8307, grad_fn=<AddBackward0>)\n",
      "tensor(7.8994, grad_fn=<AddBackward0>)\n",
      "tensor(7.8579, grad_fn=<AddBackward0>)\n",
      "tensor(7.8167, grad_fn=<AddBackward0>)\n",
      "tensor(7.8209, grad_fn=<AddBackward0>)\n",
      "tensor(7.8021, grad_fn=<AddBackward0>)\n",
      "tensor(7.8471, grad_fn=<AddBackward0>)\n",
      "tensor(7.8374, grad_fn=<AddBackward0>)\n",
      "tensor(7.8458, grad_fn=<AddBackward0>)\n",
      "tensor(7.8400, grad_fn=<AddBackward0>)\n",
      "tensor(7.8184, grad_fn=<AddBackward0>)\n",
      "tensor(7.8512, grad_fn=<AddBackward0>)\n",
      "tensor(7.8402, grad_fn=<AddBackward0>)\n",
      "tensor(7.8434, grad_fn=<AddBackward0>)\n",
      "tensor(7.8141, grad_fn=<AddBackward0>)\n",
      "tensor(7.8592, grad_fn=<AddBackward0>)\n",
      "tensor(7.7741, grad_fn=<AddBackward0>)\n",
      "tensor(7.7861, grad_fn=<AddBackward0>)\n",
      "tensor(7.8279, grad_fn=<AddBackward0>)\n",
      "tensor(7.8165, grad_fn=<AddBackward0>)\n",
      "tensor(7.8275, grad_fn=<AddBackward0>)\n",
      "tensor(7.8593, grad_fn=<AddBackward0>)\n",
      "tensor(7.8177, grad_fn=<AddBackward0>)\n",
      "tensor(7.8199, grad_fn=<AddBackward0>)\n",
      "tensor(7.7766, grad_fn=<AddBackward0>)\n",
      "tensor(7.8361, grad_fn=<AddBackward0>)\n",
      "tensor(7.7940, grad_fn=<AddBackward0>)\n",
      "tensor(7.7763, grad_fn=<AddBackward0>)\n",
      "tensor(7.8187, grad_fn=<AddBackward0>)\n",
      "tensor(7.8536, grad_fn=<AddBackward0>)\n",
      "tensor(7.7767, grad_fn=<AddBackward0>)\n",
      "tensor(7.8195, grad_fn=<AddBackward0>)\n",
      "tensor(7.8200, grad_fn=<AddBackward0>)\n",
      "tensor(7.8440, grad_fn=<AddBackward0>)\n",
      "tensor(7.8173, grad_fn=<AddBackward0>)\n",
      "tensor(7.8220, grad_fn=<AddBackward0>)\n",
      "tensor(7.7908, grad_fn=<AddBackward0>)\n",
      "tensor(7.7489, grad_fn=<AddBackward0>)\n",
      "tensor(7.8132, grad_fn=<AddBackward0>)\n",
      "tensor(7.9132, grad_fn=<AddBackward0>)\n",
      "tensor(7.8061, grad_fn=<AddBackward0>)\n",
      "tensor(7.8528, grad_fn=<AddBackward0>)\n",
      "tensor(7.8007, grad_fn=<AddBackward0>)\n",
      "tensor(7.7799, grad_fn=<AddBackward0>)\n",
      "tensor(7.8360, grad_fn=<AddBackward0>)\n",
      "tensor(7.8345, grad_fn=<AddBackward0>)\n",
      "tensor(7.8204, grad_fn=<AddBackward0>)\n",
      "tensor(7.8789, grad_fn=<AddBackward0>)\n",
      "tensor(7.7940, grad_fn=<AddBackward0>)\n",
      "tensor(7.8069, grad_fn=<AddBackward0>)\n",
      "tensor(7.8608, grad_fn=<AddBackward0>)\n",
      "tensor(7.8083, grad_fn=<AddBackward0>)\n",
      "tensor(7.8270, grad_fn=<AddBackward0>)\n",
      "tensor(7.8477, grad_fn=<AddBackward0>)\n",
      "tensor(7.7554, grad_fn=<AddBackward0>)\n",
      "tensor(7.8210, grad_fn=<AddBackward0>)\n",
      "tensor(7.8699, grad_fn=<AddBackward0>)\n",
      "tensor(7.7970, grad_fn=<AddBackward0>)\n",
      "tensor(7.8468, grad_fn=<AddBackward0>)\n",
      "tensor(7.7969, grad_fn=<AddBackward0>)\n",
      "tensor(7.8529, grad_fn=<AddBackward0>)\n",
      "tensor(7.8122, grad_fn=<AddBackward0>)\n",
      "tensor(7.8332, grad_fn=<AddBackward0>)\n",
      "tensor(7.8149, grad_fn=<AddBackward0>)\n",
      "tensor(7.7995, grad_fn=<AddBackward0>)\n",
      "tensor(7.8117, grad_fn=<AddBackward0>)\n",
      "tensor(7.8858, grad_fn=<AddBackward0>)\n",
      "tensor(7.8835, grad_fn=<AddBackward0>)\n",
      "tensor(7.8080, grad_fn=<AddBackward0>)\n",
      "tensor(7.7441, grad_fn=<AddBackward0>)\n",
      "tensor(7.7231, grad_fn=<AddBackward0>)\n",
      "tensor(7.7974, grad_fn=<AddBackward0>)\n",
      "tensor(7.8585, grad_fn=<AddBackward0>)\n",
      "tensor(7.8182, grad_fn=<AddBackward0>)\n",
      "tensor(7.7501, grad_fn=<AddBackward0>)\n",
      "tensor(7.8199, grad_fn=<AddBackward0>)\n",
      "tensor(7.8295, grad_fn=<AddBackward0>)\n",
      "tensor(7.8167, grad_fn=<AddBackward0>)\n",
      "tensor(7.9071, grad_fn=<AddBackward0>)\n",
      "tensor(7.8579, grad_fn=<AddBackward0>)\n",
      "tensor(7.8256, grad_fn=<AddBackward0>)\n",
      "tensor(7.8466, grad_fn=<AddBackward0>)\n",
      "tensor(7.7826, grad_fn=<AddBackward0>)\n",
      "tensor(7.8626, grad_fn=<AddBackward0>)\n",
      "tensor(7.8232, grad_fn=<AddBackward0>)\n",
      "tensor(7.8252, grad_fn=<AddBackward0>)\n",
      "tensor(7.8206, grad_fn=<AddBackward0>)\n",
      "tensor(7.8048, grad_fn=<AddBackward0>)\n",
      "tensor(7.7846, grad_fn=<AddBackward0>)\n",
      "tensor(7.7641, grad_fn=<AddBackward0>)\n",
      "tensor(7.8745, grad_fn=<AddBackward0>)\n",
      "tensor(7.8048, grad_fn=<AddBackward0>)\n",
      "tensor(7.7873, grad_fn=<AddBackward0>)\n",
      "tensor(7.7892, grad_fn=<AddBackward0>)\n",
      "tensor(7.8143, grad_fn=<AddBackward0>)\n",
      "tensor(7.8128, grad_fn=<AddBackward0>)\n",
      "tensor(7.8330, grad_fn=<AddBackward0>)\n",
      "tensor(7.8463, grad_fn=<AddBackward0>)\n",
      "tensor(7.8216, grad_fn=<AddBackward0>)\n",
      "tensor(7.8796, grad_fn=<AddBackward0>)\n",
      "tensor(7.8334, grad_fn=<AddBackward0>)\n",
      "tensor(7.8099, grad_fn=<AddBackward0>)\n",
      "tensor(7.8409, grad_fn=<AddBackward0>)\n",
      "tensor(7.8252, grad_fn=<AddBackward0>)\n",
      "tensor(7.8557, grad_fn=<AddBackward0>)\n",
      "tensor(7.8174, grad_fn=<AddBackward0>)\n",
      "tensor(7.8304, grad_fn=<AddBackward0>)\n",
      "tensor(7.8419, grad_fn=<AddBackward0>)\n",
      "tensor(7.8282, grad_fn=<AddBackward0>)\n",
      "tensor(7.8328, grad_fn=<AddBackward0>)\n",
      "tensor(7.7803, grad_fn=<AddBackward0>)\n",
      "tensor(7.8424, grad_fn=<AddBackward0>)\n",
      "tensor(7.9380, grad_fn=<AddBackward0>)\n",
      "tensor(7.7961, grad_fn=<AddBackward0>)\n",
      "tensor(7.7868, grad_fn=<AddBackward0>)\n",
      "tensor(7.7992, grad_fn=<AddBackward0>)\n",
      "tensor(7.7996, grad_fn=<AddBackward0>)\n",
      "tensor(7.8052, grad_fn=<AddBackward0>)\n",
      "tensor(7.7542, grad_fn=<AddBackward0>)\n",
      "tensor(7.8771, grad_fn=<AddBackward0>)\n",
      "tensor(7.8078, grad_fn=<AddBackward0>)\n",
      "tensor(7.8031, grad_fn=<AddBackward0>)\n",
      "tensor(7.8221, grad_fn=<AddBackward0>)\n",
      "tensor(7.8116, grad_fn=<AddBackward0>)\n",
      "tensor(7.8316, grad_fn=<AddBackward0>)\n",
      "tensor(7.8082, grad_fn=<AddBackward0>)\n",
      "tensor(7.8319, grad_fn=<AddBackward0>)\n",
      "tensor(7.7940, grad_fn=<AddBackward0>)\n",
      "tensor(7.8309, grad_fn=<AddBackward0>)\n",
      "tensor(7.8342, grad_fn=<AddBackward0>)\n",
      "tensor(7.8735, grad_fn=<AddBackward0>)\n",
      "tensor(7.7846, grad_fn=<AddBackward0>)\n",
      "tensor(7.8337, grad_fn=<AddBackward0>)\n",
      "tensor(7.8207, grad_fn=<AddBackward0>)\n",
      "tensor(7.8414, grad_fn=<AddBackward0>)\n",
      "tensor(7.7686, grad_fn=<AddBackward0>)\n",
      "tensor(7.8347, grad_fn=<AddBackward0>)\n",
      "tensor(7.8591, grad_fn=<AddBackward0>)\n",
      "tensor(7.8172, grad_fn=<AddBackward0>)\n",
      "tensor(7.8077, grad_fn=<AddBackward0>)\n",
      "tensor(7.8086, grad_fn=<AddBackward0>)\n",
      "tensor(7.8233, grad_fn=<AddBackward0>)\n",
      "tensor(7.8274, grad_fn=<AddBackward0>)\n",
      "tensor(7.7913, grad_fn=<AddBackward0>)\n",
      "tensor(7.7592, grad_fn=<AddBackward0>)\n",
      "tensor(7.8102, grad_fn=<AddBackward0>)\n",
      "tensor(7.8639, grad_fn=<AddBackward0>)\n",
      "tensor(7.7659, grad_fn=<AddBackward0>)\n",
      "tensor(7.7757, grad_fn=<AddBackward0>)\n",
      "tensor(7.8391, grad_fn=<AddBackward0>)\n",
      "tensor(7.8621, grad_fn=<AddBackward0>)\n",
      "tensor(7.8450, grad_fn=<AddBackward0>)\n",
      "tensor(7.8067, grad_fn=<AddBackward0>)\n",
      "tensor(7.7936, grad_fn=<AddBackward0>)\n",
      "tensor(7.8395, grad_fn=<AddBackward0>)\n",
      "tensor(7.7997, grad_fn=<AddBackward0>)\n",
      "tensor(7.8492, grad_fn=<AddBackward0>)\n",
      "tensor(7.7783, grad_fn=<AddBackward0>)\n",
      "tensor(7.8446, grad_fn=<AddBackward0>)\n",
      "tensor(7.7401, grad_fn=<AddBackward0>)\n",
      "tensor(7.9088, grad_fn=<AddBackward0>)\n",
      "tensor(7.8071, grad_fn=<AddBackward0>)\n",
      "tensor(7.9049, grad_fn=<AddBackward0>)\n",
      "tensor(7.8187, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.8380, grad_fn=<AddBackward0>)\n",
      "tensor(7.7953, grad_fn=<AddBackward0>)\n",
      "tensor(7.7977, grad_fn=<AddBackward0>)\n",
      "tensor(7.7704, grad_fn=<AddBackward0>)\n",
      "tensor(7.7847, grad_fn=<AddBackward0>)\n",
      "tensor(7.7659, grad_fn=<AddBackward0>)\n",
      "tensor(7.8482, grad_fn=<AddBackward0>)\n",
      "tensor(7.8468, grad_fn=<AddBackward0>)\n",
      "tensor(7.9099, grad_fn=<AddBackward0>)\n",
      "tensor(7.7952, grad_fn=<AddBackward0>)\n",
      "tensor(7.7791, grad_fn=<AddBackward0>)\n",
      "tensor(7.8046, grad_fn=<AddBackward0>)\n",
      "tensor(7.8394, grad_fn=<AddBackward0>)\n",
      "tensor(7.8095, grad_fn=<AddBackward0>)\n",
      "tensor(7.8361, grad_fn=<AddBackward0>)\n",
      "tensor(7.8239, grad_fn=<AddBackward0>)\n",
      "tensor(7.7516, grad_fn=<AddBackward0>)\n",
      "tensor(7.8450, grad_fn=<AddBackward0>)\n",
      "tensor(7.8214, grad_fn=<AddBackward0>)\n",
      "tensor(7.9013, grad_fn=<AddBackward0>)\n",
      "tensor(7.7651, grad_fn=<AddBackward0>)\n",
      "tensor(7.8183, grad_fn=<AddBackward0>)\n",
      "tensor(7.8442, grad_fn=<AddBackward0>)\n",
      "tensor(7.8555, grad_fn=<AddBackward0>)\n",
      "tensor(7.8839, grad_fn=<AddBackward0>)\n",
      "tensor(7.8470, grad_fn=<AddBackward0>)\n",
      "tensor(7.8094, grad_fn=<AddBackward0>)\n",
      "tensor(7.8567, grad_fn=<AddBackward0>)\n",
      "tensor(7.8020, grad_fn=<AddBackward0>)\n",
      "tensor(7.8495, grad_fn=<AddBackward0>)\n",
      "tensor(7.8171, grad_fn=<AddBackward0>)\n",
      "tensor(7.8674, grad_fn=<AddBackward0>)\n",
      "tensor(7.8282, grad_fn=<AddBackward0>)\n",
      "tensor(7.7646, grad_fn=<AddBackward0>)\n",
      "tensor(7.8100, grad_fn=<AddBackward0>)\n",
      "tensor(7.7972, grad_fn=<AddBackward0>)\n",
      "tensor(7.8461, grad_fn=<AddBackward0>)\n",
      "tensor(7.7652, grad_fn=<AddBackward0>)\n",
      "tensor(7.8002, grad_fn=<AddBackward0>)\n",
      "tensor(7.7819, grad_fn=<AddBackward0>)\n",
      "tensor(7.7798, grad_fn=<AddBackward0>)\n",
      "tensor(7.8088, grad_fn=<AddBackward0>)\n",
      "tensor(7.8466, grad_fn=<AddBackward0>)\n",
      "tensor(7.8259, grad_fn=<AddBackward0>)\n",
      "tensor(7.7691, grad_fn=<AddBackward0>)\n",
      "tensor(7.7799, grad_fn=<AddBackward0>)\n",
      "tensor(7.8131, grad_fn=<AddBackward0>)\n",
      "tensor(7.7852, grad_fn=<AddBackward0>)\n",
      "tensor(7.7583, grad_fn=<AddBackward0>)\n",
      "tensor(7.8997, grad_fn=<AddBackward0>)\n",
      "tensor(7.8243, grad_fn=<AddBackward0>)\n",
      "tensor(7.8243, grad_fn=<AddBackward0>)\n",
      "tensor(7.8057, grad_fn=<AddBackward0>)\n",
      "tensor(7.8493, grad_fn=<AddBackward0>)\n",
      "tensor(7.7962, grad_fn=<AddBackward0>)\n",
      "tensor(7.8566, grad_fn=<AddBackward0>)\n",
      "tensor(7.8765, grad_fn=<AddBackward0>)\n",
      "tensor(7.8078, grad_fn=<AddBackward0>)\n",
      "tensor(7.8565, grad_fn=<AddBackward0>)\n",
      "tensor(7.7785, grad_fn=<AddBackward0>)\n",
      "tensor(7.8717, grad_fn=<AddBackward0>)\n",
      "tensor(7.8731, grad_fn=<AddBackward0>)\n",
      "tensor(7.8344, grad_fn=<AddBackward0>)\n",
      "tensor(7.7776, grad_fn=<AddBackward0>)\n",
      "tensor(7.7967, grad_fn=<AddBackward0>)\n",
      "tensor(7.8102, grad_fn=<AddBackward0>)\n",
      "tensor(7.8348, grad_fn=<AddBackward0>)\n",
      "tensor(7.8291, grad_fn=<AddBackward0>)\n",
      "tensor(7.8446, grad_fn=<AddBackward0>)\n",
      "tensor(7.8600, grad_fn=<AddBackward0>)\n",
      "tensor(7.8772, grad_fn=<AddBackward0>)\n",
      "tensor(7.7965, grad_fn=<AddBackward0>)\n",
      "tensor(7.8405, grad_fn=<AddBackward0>)\n",
      "tensor(7.7924, grad_fn=<AddBackward0>)\n",
      "tensor(7.8042, grad_fn=<AddBackward0>)\n",
      "tensor(7.8193, grad_fn=<AddBackward0>)\n",
      "tensor(7.8422, grad_fn=<AddBackward0>)\n",
      "tensor(7.8411, grad_fn=<AddBackward0>)\n",
      "tensor(7.8114, grad_fn=<AddBackward0>)\n",
      "tensor(7.7984, grad_fn=<AddBackward0>)\n",
      "tensor(7.8166, grad_fn=<AddBackward0>)\n",
      "tensor(7.8058, grad_fn=<AddBackward0>)\n",
      "tensor(7.7927, grad_fn=<AddBackward0>)\n",
      "tensor(7.8210, grad_fn=<AddBackward0>)\n",
      "tensor(7.8718, grad_fn=<AddBackward0>)\n",
      "tensor(7.7856, grad_fn=<AddBackward0>)\n",
      "tensor(7.8899, grad_fn=<AddBackward0>)\n",
      "tensor(7.8278, grad_fn=<AddBackward0>)\n",
      "tensor(7.8000, grad_fn=<AddBackward0>)\n",
      "tensor(7.8120, grad_fn=<AddBackward0>)\n",
      "tensor(7.8004, grad_fn=<AddBackward0>)\n",
      "tensor(7.8228, grad_fn=<AddBackward0>)\n",
      "tensor(7.8174, grad_fn=<AddBackward0>)\n",
      "tensor(7.7618, grad_fn=<AddBackward0>)\n",
      "tensor(7.7708, grad_fn=<AddBackward0>)\n",
      "tensor(7.8229, grad_fn=<AddBackward0>)\n",
      "tensor(7.8201, grad_fn=<AddBackward0>)\n",
      "tensor(7.7714, grad_fn=<AddBackward0>)\n",
      "tensor(7.8338, grad_fn=<AddBackward0>)\n",
      "tensor(7.8092, grad_fn=<AddBackward0>)\n",
      "tensor(7.8309, grad_fn=<AddBackward0>)\n",
      "tensor(7.7930, grad_fn=<AddBackward0>)\n",
      "tensor(7.8194, grad_fn=<AddBackward0>)\n",
      "tensor(7.8225, grad_fn=<AddBackward0>)\n",
      "tensor(7.8118, grad_fn=<AddBackward0>)\n",
      "tensor(7.9032, grad_fn=<AddBackward0>)\n",
      "tensor(7.7434, grad_fn=<AddBackward0>)\n",
      "tensor(7.7620, grad_fn=<AddBackward0>)\n",
      "tensor(7.7672, grad_fn=<AddBackward0>)\n",
      "tensor(7.8633, grad_fn=<AddBackward0>)\n",
      "tensor(7.8012, grad_fn=<AddBackward0>)\n",
      "tensor(7.8850, grad_fn=<AddBackward0>)\n",
      "tensor(7.8232, grad_fn=<AddBackward0>)\n",
      "tensor(7.8158, grad_fn=<AddBackward0>)\n",
      "tensor(7.8378, grad_fn=<AddBackward0>)\n",
      "tensor(7.7969, grad_fn=<AddBackward0>)\n",
      "tensor(7.7678, grad_fn=<AddBackward0>)\n",
      "tensor(7.7976, grad_fn=<AddBackward0>)\n",
      "tensor(7.7922, grad_fn=<AddBackward0>)\n",
      "tensor(7.8532, grad_fn=<AddBackward0>)\n",
      "tensor(7.8151, grad_fn=<AddBackward0>)\n",
      "tensor(7.8167, grad_fn=<AddBackward0>)\n",
      "tensor(7.8388, grad_fn=<AddBackward0>)\n",
      "tensor(7.8661, grad_fn=<AddBackward0>)\n",
      "tensor(7.7888, grad_fn=<AddBackward0>)\n",
      "tensor(7.7908, grad_fn=<AddBackward0>)\n",
      "tensor(7.8104, grad_fn=<AddBackward0>)\n",
      "tensor(7.7737, grad_fn=<AddBackward0>)\n",
      "tensor(7.7579, grad_fn=<AddBackward0>)\n",
      "tensor(7.8316, grad_fn=<AddBackward0>)\n",
      "tensor(7.8167, grad_fn=<AddBackward0>)\n",
      "tensor(7.8149, grad_fn=<AddBackward0>)\n",
      "tensor(7.7830, grad_fn=<AddBackward0>)\n",
      "tensor(7.8334, grad_fn=<AddBackward0>)\n",
      "tensor(7.8645, grad_fn=<AddBackward0>)\n",
      "tensor(7.8502, grad_fn=<AddBackward0>)\n",
      "tensor(7.8103, grad_fn=<AddBackward0>)\n",
      "tensor(7.8671, grad_fn=<AddBackward0>)\n",
      "tensor(7.7764, grad_fn=<AddBackward0>)\n",
      "tensor(7.7518, grad_fn=<AddBackward0>)\n",
      "tensor(7.7895, grad_fn=<AddBackward0>)\n",
      "tensor(7.8104, grad_fn=<AddBackward0>)\n",
      "tensor(7.7934, grad_fn=<AddBackward0>)\n",
      "tensor(7.7892, grad_fn=<AddBackward0>)\n",
      "tensor(7.9063, grad_fn=<AddBackward0>)\n",
      "tensor(7.8171, grad_fn=<AddBackward0>)\n",
      "tensor(7.8236, grad_fn=<AddBackward0>)\n",
      "tensor(7.8113, grad_fn=<AddBackward0>)\n",
      "tensor(7.7986, grad_fn=<AddBackward0>)\n",
      "tensor(7.7955, grad_fn=<AddBackward0>)\n",
      "tensor(7.8149, grad_fn=<AddBackward0>)\n",
      "tensor(7.7786, grad_fn=<AddBackward0>)\n",
      "tensor(7.8176, grad_fn=<AddBackward0>)\n",
      "tensor(7.7601, grad_fn=<AddBackward0>)\n",
      "tensor(7.8356, grad_fn=<AddBackward0>)\n",
      "tensor(7.8456, grad_fn=<AddBackward0>)\n",
      "tensor(7.9108, grad_fn=<AddBackward0>)\n",
      "tensor(7.8446, grad_fn=<AddBackward0>)\n",
      "tensor(7.8583, grad_fn=<AddBackward0>)\n",
      "tensor(7.8175, grad_fn=<AddBackward0>)\n",
      "tensor(7.7926, grad_fn=<AddBackward0>)\n",
      "tensor(7.8230, grad_fn=<AddBackward0>)\n",
      "tensor(7.8316, grad_fn=<AddBackward0>)\n",
      "tensor(7.8440, grad_fn=<AddBackward0>)\n",
      "tensor(7.7943, grad_fn=<AddBackward0>)\n",
      "tensor(7.8453, grad_fn=<AddBackward0>)\n",
      "tensor(7.8051, grad_fn=<AddBackward0>)\n",
      "tensor(7.8397, grad_fn=<AddBackward0>)\n",
      "tensor(7.8089, grad_fn=<AddBackward0>)\n",
      "tensor(7.7783, grad_fn=<AddBackward0>)\n",
      "tensor(7.8250, grad_fn=<AddBackward0>)\n",
      "tensor(7.7811, grad_fn=<AddBackward0>)\n",
      "tensor(7.8421, grad_fn=<AddBackward0>)\n",
      "tensor(7.7793, grad_fn=<AddBackward0>)\n",
      "tensor(7.8049, grad_fn=<AddBackward0>)\n",
      "tensor(7.8416, grad_fn=<AddBackward0>)\n",
      "tensor(7.8865, grad_fn=<AddBackward0>)\n",
      "tensor(7.8346, grad_fn=<AddBackward0>)\n",
      "tensor(7.8225, grad_fn=<AddBackward0>)\n",
      "tensor(7.8515, grad_fn=<AddBackward0>)\n",
      "tensor(7.8065, grad_fn=<AddBackward0>)\n",
      "tensor(7.7918, grad_fn=<AddBackward0>)\n",
      "tensor(7.8487, grad_fn=<AddBackward0>)\n",
      "tensor(7.8562, grad_fn=<AddBackward0>)\n",
      "tensor(7.8246, grad_fn=<AddBackward0>)\n",
      "tensor(7.8186, grad_fn=<AddBackward0>)\n",
      "tensor(7.7911, grad_fn=<AddBackward0>)\n",
      "tensor(7.8516, grad_fn=<AddBackward0>)\n",
      "tensor(7.7810, grad_fn=<AddBackward0>)\n",
      "tensor(7.8038, grad_fn=<AddBackward0>)\n",
      "tensor(7.8270, grad_fn=<AddBackward0>)\n",
      "tensor(7.8087, grad_fn=<AddBackward0>)\n",
      "tensor(7.8013, grad_fn=<AddBackward0>)\n",
      "tensor(7.8133, grad_fn=<AddBackward0>)\n",
      "tensor(7.8186, grad_fn=<AddBackward0>)\n",
      "tensor(7.8512, grad_fn=<AddBackward0>)\n",
      "tensor(7.8622, grad_fn=<AddBackward0>)\n",
      "tensor(7.9004, grad_fn=<AddBackward0>)\n",
      "tensor(7.8197, grad_fn=<AddBackward0>)\n",
      "tensor(7.8315, grad_fn=<AddBackward0>)\n",
      "tensor(7.8148, grad_fn=<AddBackward0>)\n",
      "tensor(7.8502, grad_fn=<AddBackward0>)\n",
      "tensor(7.8035, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1859, -2.6643]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conditional_probability_action(x):\n",
    "    prm = (100.0, 0.1)\n",
    "    x = prm[0]*(- prm[1] + x)\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "a = torch.tensor([0.2])\n",
    "b = torch.tensor([[torch.logit(torch.tensor([0.99])), 1.0]])\n",
    "y = torch.tensor([0])\n",
    "\n",
    "revise_belief(a=a, \n",
    "              y=y, \n",
    "              b=b,\n",
    "              conditional_probability_action=conditional_probability_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1915350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
