{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c08ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import scipy\n",
    "\n",
    "from torch import distributions as dist\n",
    "from scipy.special import logsumexp, expit\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d020466-5a30-49d2-ade3-c39478e209db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3, 3))\n",
    "b = torch.rand((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dec4896-a002-468c-a0fd-e9f594a492a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.8267)\n"
     ]
    }
   ],
   "source": [
    "var = 0\n",
    "for i in range(3):\n",
    "    var -= (a[i] * b[i]).sum()\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e94d2e1f-fa64-4104-9ed2-a34fd5eea6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8267)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(a, b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0e9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = np.finfo(np.float64).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e698a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_product(*arrays):\n",
    "\n",
    "    la = len(arrays)\n",
    "    dtype = np.result_type(*arrays)\n",
    "    arr = np.empty([len(a) for a in arrays] + [la], dtype=dtype)\n",
    "    for i, a in enumerate(np.ix_(*arrays)):\n",
    "        arr[..., i] = a\n",
    "    return arr.reshape(-1, la)\n",
    "\n",
    "def cp_grid_param(grid_size, bounds, methods):\n",
    "    \n",
    "    bds = np.asarray(bounds)\n",
    "    mths = np.asarray(methods)\n",
    "\n",
    "    diff = bds[:, 1] - bds[:, 0] > 0\n",
    "    not_diff = np.invert(diff)\n",
    "\n",
    "    values = np.atleast_2d(\n",
    "        [m(*b, num=grid_size) for (b, m) in\n",
    "         zip(bds[diff], mths[diff])])\n",
    "\n",
    "    var = cartesian_product(*values)\n",
    "    grid = np.zeros((max(1, len(var)), len(bds)))\n",
    "    if np.sum(diff):\n",
    "        grid[:, diff] = var\n",
    "    if np.sum(not_diff):\n",
    "        grid[:, not_diff] = bds[not_diff, 0]\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "bounds = [1., 1.], [0.0, 0.5]\n",
    "grid = cp_grid_param(grid_size=100, bounds=bounds, methods=(np.geomspace, np.linspace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd176411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34a2849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010559783919909747 0.008949329037300823\n",
      "0.009718164172281003\n"
     ]
    }
   ],
   "source": [
    "n_pres = np.array([2, 0])\n",
    "delta = np.array([1., 0.])\n",
    "\n",
    "n_item = len(n_pres)\n",
    "n_param = len(bounds)\n",
    "\n",
    "prior = np.ones(len(grid))\n",
    "prior -= scipy.special.logsumexp(prior)\n",
    "\n",
    "item = 0\n",
    "\n",
    "init_fr, rep_effect = grid.T\n",
    "logp_success = -init_fr*(1-rep_effect)**(n_pres[item]-1)*delta[item]\n",
    "\n",
    "post_success = prior + logp_success\n",
    "post_success -= logsumexp(post_success)\n",
    "ig_success = entropy(np.exp(post_success), np.exp(prior))\n",
    "\n",
    "post_failure = prior + np.log(1 - np.exp(logp_success))\n",
    "post_failure -= logsumexp(post_failure)\n",
    "ig_failure = entropy(np.exp(post_failure), np.exp(prior))\n",
    "\n",
    "marg_p_success = np.sum(np.exp(prior + logp_success))\n",
    "\n",
    "print(ig_success, ig_failure)\n",
    "print(marg_p_success*ig_success + (1 - marg_p_success)*ig_failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45caf8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f222376c908452e8bd2cfee7c5014d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1070, 0.1070, 0.0975, 0.1394, 0.5491])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "n_sample = 10\n",
    "lr = 0.5\n",
    "\n",
    "n_pres = np.arange(0, 5)\n",
    "delta = np.ones(len(n_pres))\n",
    "\n",
    "n_item = len(n_pres)\n",
    "n_param = len(bounds)\n",
    "\n",
    "prior_action = dist.Categorical(logits=torch.ones(n_item))\n",
    "\n",
    "logits_action = torch.nn.Parameter(torch.ones(n_item))\n",
    "\n",
    "opt = torch.optim.Adam([logits_action, ], lr=lr)\n",
    "\n",
    "prior = np.ones(len(grid))\n",
    "prior -= logsumexp(prior)\n",
    "\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for _ in range(n_epoch):\n",
    "\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        q = dist.Categorical(logits=logits_action)\n",
    "        item_samples = q.sample((n_sample, ))\n",
    "        \n",
    "        sum_terms = 0\n",
    "        \n",
    "        for item in item_samples:\n",
    "            if n_pres[item] == 0:\n",
    "                expected_ig = 0.0\n",
    "            else:\n",
    "                init_fr, rep_effect = grid.T\n",
    "                logp_success = -init_fr*(1-rep_effect)**(n_pres[item]-1)*delta[item]\n",
    "\n",
    "                post_success = prior + logp_success\n",
    "                post_success -= logsumexp(post_success)\n",
    "                ig_success = entropy(np.exp(post_success), np.exp(prior))\n",
    "\n",
    "                post_failure = prior + np.log(1 - np.exp(logp_success))\n",
    "                post_failure -= logsumexp(post_failure)\n",
    "                ig_failure = entropy(np.exp(post_failure), np.exp(prior))\n",
    "\n",
    "                marg_p_success = np.sum(np.exp(prior + logp_success))\n",
    "\n",
    "                expected_ig = marg_p_success*ig_success + (1 - marg_p_success)*ig_failure\n",
    "\n",
    "            sum_terms += q.log_prob(item).exp() * expected_ig\n",
    "        \n",
    "        loss = - torch.log(sum_terms) + torch.distributions.kl_divergence(q, prior_action)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "        pbar.update()\n",
    "\n",
    "dist.Categorical(logits=logits_action).probs.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd58d49",
   "metadata": {},
   "source": [
    "### Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69882020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] 0.012636287668632572\n",
      "[0 1] 0.009718164172281003\n",
      "[1 0] 0.009718164172281003\n",
      "[1 1] 0.05421082840397357\n"
     ]
    }
   ],
   "source": [
    "current_n_pres = np.arange(1, 3)\n",
    "current_delta = np.ones(len(current_n_pres))\n",
    "\n",
    "n_item = len(current_n_pres)\n",
    "n_param = len(bounds)\n",
    "\n",
    "prior = np.ones(len(grid))\n",
    "prior -= scipy.special.logsumexp(prior)\n",
    "\n",
    "n_step = 2\n",
    "inter_trial_interval = 2.\n",
    "\n",
    "all_traj = cartesian_product(*[np.arange(n_item) for _ in range(n_step)])\n",
    "results = []\n",
    "\n",
    "for traj in all_traj:\n",
    "    expected_ig = 0. \n",
    "    \n",
    "    n_pres = deepcopy(current_n_pres)\n",
    "    delta = deepcopy(current_delta)\n",
    "    \n",
    "    for item in traj:\n",
    "\n",
    "        if n_pres[item] == 0:\n",
    "            expected_ig += 0.0\n",
    "        else:\n",
    "            init_fr, rep_effect = grid.T\n",
    "            logp_success = -init_fr*(1-rep_effect)**(n_pres[item]-1)*delta[item]\n",
    "\n",
    "            post_success = prior + logp_success\n",
    "            post_success -= logsumexp(post_success)\n",
    "            ig_success = entropy(np.exp(post_success), np.exp(prior))\n",
    "\n",
    "            post_failure = prior + np.log(1 - np.exp(logp_success))\n",
    "            post_failure -= logsumexp(post_failure)\n",
    "            ig_failure = entropy(np.exp(post_failure), np.exp(prior))\n",
    "\n",
    "            marg_p_success = np.sum(np.exp(prior + logp_success))\n",
    "\n",
    "            expected_ig += marg_p_success*ig_success + (1 - marg_p_success)*ig_failure\n",
    "        \n",
    "        n_pres[item] += 1\n",
    "        delta[item] = inter_trial_interval\n",
    "    \n",
    "    print(traj, expected_ig)\n",
    "    \n",
    "    results.append(expected_ig)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ad54d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db325e33e9440ebab18cfd8c113df08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epoch = 1000\n",
    "n_sample = 10\n",
    "lr = 0.2\n",
    "\n",
    "current_n_pres = np.arange(1, 3)\n",
    "current_delta = np.ones(len(current_n_pres))\n",
    "\n",
    "n_item = len(current_n_pres)\n",
    "n_param = len(bounds)\n",
    "\n",
    "n_step = 2\n",
    "inter_trial_interval = 3.\n",
    "\n",
    "prior_action = dist.Categorical(logits=torch.ones(n_item))\n",
    "\n",
    "logits_action = torch.nn.Parameter(torch.ones((n_step, n_item)))\n",
    "\n",
    "opt = torch.optim.Adam([logits_action, ], lr=lr)\n",
    "\n",
    "prior = np.ones(len(grid))\n",
    "prior -= logsumexp(prior)\n",
    "\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for _ in range(n_epoch):\n",
    "\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        for smp in range(n_sample):\n",
    "            \n",
    "            n_pres = deepcopy(current_n_pres)\n",
    "            delta = deepcopy(current_delta)\n",
    "            \n",
    "            sum_terms = 0\n",
    "            sum_kl_div_prior = 0\n",
    "            \n",
    "            for t in range(n_step):\n",
    "                        \n",
    "                q = dist.Categorical(logits=logits_action[t])\n",
    "                item = q.sample()\n",
    "\n",
    "                if n_pres[item] == 0:\n",
    "                    expected_ig = 0.0\n",
    "\n",
    "                else:\n",
    "                    init_fr, rep_effect = grid.T\n",
    "                    logp_success = -init_fr*(1-rep_effect)**(n_pres[item]-1)*delta[item]\n",
    "\n",
    "                    post_success = prior + logp_success\n",
    "                    post_success -= logsumexp(post_success)\n",
    "                    ig_success = entropy(np.exp(post_success), np.exp(prior))\n",
    "\n",
    "                    post_failure = prior + np.log(1 - np.exp(logp_success))\n",
    "                    post_failure -= logsumexp(post_failure)\n",
    "                    ig_failure = entropy(np.exp(post_failure), np.exp(prior))\n",
    "\n",
    "                    marg_p_success = np.sum(np.exp(prior + logp_success))\n",
    "\n",
    "                    expected_ig = marg_p_success*ig_success + (1 - marg_p_success)*ig_failure\n",
    "\n",
    "                sum_terms += q.log_prob(item).exp() * expected_ig      \n",
    "                        \n",
    "                n_pres[item] += 1\n",
    "                delta[item] = inter_trial_interval\n",
    "                \n",
    "                sum_kl_div_prior += torch.distributions.kl_divergence(q, prior_action)\n",
    "\n",
    "            loss = - torch.log(sum_terms)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "        pbar.update()\n",
    "\n",
    "dist.Categorical(logits=logits_action).probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9ed012",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item = 4\n",
    "\n",
    "current_n_pres = np.ones(n_item)\n",
    "current_delta = np.ones(n_item)\n",
    "\n",
    "n_param = len(bounds)\n",
    "\n",
    "prior = np.ones(len(grid))\n",
    "prior -= scipy.special.logsumexp(prior)\n",
    "\n",
    "n_step = 5\n",
    "inter_trial_interval = 0.1\n",
    "\n",
    "all_traj = cartesian_product(*[np.arange(n_item) for _ in range(n_step)])\n",
    "results = []\n",
    "\n",
    "for traj in tqdm(all_traj):\n",
    "    expected_ig = 0. \n",
    "    \n",
    "    n_pres = deepcopy(current_n_pres)\n",
    "    delta = deepcopy(current_delta)\n",
    "    \n",
    "    for item in traj:\n",
    "\n",
    "        if n_pres[item] == 0:\n",
    "            expected_ig += 0.0\n",
    "        else:\n",
    "            init_fr, rep_effect = grid.T\n",
    "            logp_success = -init_fr*(1-rep_effect)**(n_pres[item]-1)*delta[item]\n",
    "\n",
    "            post_success = prior + logp_success\n",
    "            post_success -= logsumexp(post_success)\n",
    "            ig_success = entropy(np.exp(post_success), np.exp(prior))\n",
    "\n",
    "            post_failure = prior + np.log(1 - np.exp(logp_success))\n",
    "            post_failure -= logsumexp(post_failure)\n",
    "            ig_failure = entropy(np.exp(post_failure), np.exp(prior))\n",
    "\n",
    "            marg_p_success = np.sum(np.exp(prior + logp_success))\n",
    "\n",
    "            expected_ig += marg_p_success*ig_success + (1 - marg_p_success)*ig_failure\n",
    "        \n",
    "        n_pres[item] += 1\n",
    "        delta[item] = inter_trial_interval\n",
    "    \n",
    "    # print(traj, expected_ig)\n",
    "    \n",
    "    results.append(expected_ig)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3655cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_traj[results == np.max(results)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aa4cf1",
   "metadata": {},
   "source": [
    "### Debug `deltas` computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9e9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_iter = 0\n",
    "current_ss = 0\n",
    "\n",
    "n_item = 10\n",
    "n_iter_per_session = 2\n",
    "time_per_iter = 3\n",
    "break_length = 10\n",
    "n_session = 3\n",
    "\n",
    "\n",
    "delta = np.zeros(n_item)\n",
    "n_pres = np.zeros(n_item)\n",
    "\n",
    "trajectory = []\n",
    "delays = []\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    \n",
    "    item = np.random.choice(np.arange(n_item))\n",
    "    trajectory.append(item)\n",
    "    \n",
    "    current_iter += 1\n",
    "    if current_iter >= n_iter_per_session:\n",
    "        current_iter = 0\n",
    "        current_ss += 1\n",
    "        time_elapsed = break_length\n",
    "    else:\n",
    "        time_elapsed = time_per_iter\n",
    "\n",
    "    done = False\n",
    "    if current_ss >= n_session:\n",
    "        done = True\n",
    "\n",
    "    # increase delta\n",
    "    delta += time_elapsed\n",
    "    # ...specific for item shown\n",
    "    delta[item] = time_elapsed\n",
    "    # increment number of presentation\n",
    "    n_pres[item] += 1\n",
    "    \n",
    "    delays.append(time_elapsed)\n",
    "    \n",
    "\n",
    "print(\"delays\", delays)\n",
    "print(\"n_pres\", n_pres)\n",
    "print(\"delta\", delta)\n",
    "    \n",
    "\n",
    "traj = np.asarray(trajectory)\n",
    "\n",
    "delta = np.zeros(n_item)\n",
    "n_pres = np.zeros(n_item)\n",
    "\n",
    "delays = np.tile(\n",
    "    [time_per_iter for _ in range(n_iter_per_session - 1)] + [break_length, ], \n",
    "    n_session)\n",
    "\n",
    "n_step = len(trajectory)\n",
    "\n",
    "for item in range(n_item):\n",
    "    item_pres = traj == item\n",
    "    n_pres_traj = np.sum(item_pres)\n",
    "    n_pres[item] += n_pres_traj\n",
    "    if n_pres_traj == 0:\n",
    "        delta[item] = np.sum(delays)\n",
    "    else:\n",
    "        delta[item] = np.sum(delays[np.arange(n_step)[item_pres][-1]:])\n",
    "        \n",
    "print(\"delays\", delays)\n",
    "print(\"n_pres\", n_pres)\n",
    "print(\"delta\", delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b401f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3193cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item = 3\n",
    "\n",
    "inv_temp = 10.\n",
    "\n",
    "threshold = 0.9\n",
    "\n",
    "n_iter_per_session = 2 \n",
    "time_per_iter = 2\n",
    "break_length = 10\n",
    "n_session = 2\n",
    "\n",
    "t = 0\n",
    "\n",
    "time_per_iter = 2\n",
    "n_iter_per_session = 2 \n",
    "break_length = 10\n",
    "n_session = 2\n",
    "\n",
    "t_max = n_session*n_iter_per_session\n",
    "\n",
    "t_remaining = t_max - t\n",
    "\n",
    "initial_forget_rates = np.ones(n_item) * 0.01\n",
    "repetition_rates = np.ones(n_item) * 0.2\n",
    "\n",
    "delays = np.tile(\n",
    "    [time_per_iter \n",
    "     for _ in range(n_iter_per_session - 1)] \n",
    "    + [break_length, ], \n",
    "    n_session)[t:]\n",
    "\n",
    "current_n_pres = np.zeros(n_item)\n",
    "current_delta = np.ones(n_item)\n",
    "\n",
    "print(\"N possible trajectories\", n_item**t_remaining)\n",
    "\n",
    "all_traj = cartesian_product(*[np.arange(n_item) \n",
    "                               for _ in range(t_remaining)])\n",
    "\n",
    "results = []\n",
    "\n",
    "for traj in all_traj:\n",
    "\n",
    "    n_pres = deepcopy(current_n_pres)\n",
    "    delta = deepcopy(current_delta)\n",
    "\n",
    "    for item in range(n_item):\n",
    "\n",
    "        item_pres = traj == item\n",
    "        n_pres_traj = np.sum(item_pres)\n",
    "        n_pres[item] += n_pres_traj\n",
    "        if n_pres_traj == 0:\n",
    "            delta[item] += np.sum(delays)\n",
    "        else:\n",
    "            idx_last_pres = np.arange(t_remaining)[item_pres][-1]\n",
    "            delta[item] = np.sum(delays[idx_last_pres:])\n",
    "\n",
    "    p = np.zeros(n_item)\n",
    "\n",
    "    view = n_pres > 0\n",
    "    rep = n_pres[view] - 1.\n",
    "    delta = delta[view]\n",
    "\n",
    "    init_fr = initial_forget_rates[view]\n",
    "    rep_eff = repetition_rates[view]\n",
    "\n",
    "    forget_rate = init_fr * (1 - rep_eff) ** rep\n",
    "    logp_recall = - forget_rate * delta\n",
    "\n",
    "    p[n_pres > 0] = np.exp(logp_recall)\n",
    "\n",
    "    learning_reward = np.mean(expit(inv_temp * (p - threshold)))\n",
    "    results.append(learning_reward)\n",
    "\n",
    "max_r = np.max(results)\n",
    "best = results == max_r\n",
    "print(\"Best possible reward\", max_r)\n",
    "print(\"N best\", np.sum(best))\n",
    "print(\"Best are:0\\n\", all_traj[best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96267ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002797842025756836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 25,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0]\n",
      "0.5365492649422604\n"
     ]
    }
   ],
   "source": [
    "n_item = 3\n",
    "\n",
    "inv_temp = 100.\n",
    "\n",
    "threshold = 0.9\n",
    "\n",
    "n_iter_per_session = 2 \n",
    "time_per_iter = 2\n",
    "break_length = 10\n",
    "n_session = 2\n",
    "\n",
    "t = 0\n",
    "\n",
    "time_per_iter = 2\n",
    "n_iter_per_session = 2 \n",
    "break_length = 10\n",
    "n_session = 2\n",
    "\n",
    "n_epochs = 1000\n",
    "lr = 0.5\n",
    "\n",
    "t_max = n_session*n_iter_per_session\n",
    "\n",
    "t_remaining = t_max - t\n",
    "\n",
    "logits_action = torch.nn.Parameter(torch.ones((t_remaining, n_item)))\n",
    "\n",
    "opt = torch.optim.Adam([logits_action, ], lr=lr)\n",
    "\n",
    "prior_action = dist.Categorical(logits=torch.ones(n_item))\n",
    "\n",
    "delays = np.tile(\n",
    "    [time_per_iter \n",
    "     for _ in range(n_iter_per_session - 1)] \n",
    "    + [break_length, ], \n",
    "    n_session)[t:]\n",
    "\n",
    "n_step = t_remaining\n",
    "\n",
    "with tqdm(total=n_epochs, position=1, leave=False) as pbar:\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        q = dist.Categorical(logits_action)\n",
    "        trajectories = q.sample((n_sample, ))\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for trajectory in trajectories:\n",
    "\n",
    "            n_pres = deepcopy(current_n_pres)\n",
    "            delta = deepcopy(current_delta)\n",
    "\n",
    "            for item in range(n_item):\n",
    "\n",
    "                item_pres = traj == item\n",
    "                n_pres_traj = np.sum(item_pres)\n",
    "                n_pres[item] += n_pres_traj\n",
    "                if n_pres_traj == 0:\n",
    "                    delta[item] += np.sum(delays)\n",
    "                else:\n",
    "                    idx_last_pres = np.arange(t_remaining)[item_pres][-1]\n",
    "                    delta[item] = np.sum(delays[idx_last_pres:])\n",
    "\n",
    "            p = np.zeros(n_item)\n",
    "\n",
    "            view = n_pres > 0\n",
    "            rep = n_pres[view] - 1.\n",
    "            delta = delta[view]\n",
    "\n",
    "            init_fr = initial_forget_rates[view]\n",
    "            rep_eff = repetition_rates[view]\n",
    "\n",
    "            forget_rate = init_fr * (1 - rep_eff) ** rep\n",
    "            logp_recall = - forget_rate * delta\n",
    "\n",
    "            p[n_pres > 0] = np.exp(logp_recall)\n",
    "\n",
    "            learning_reward = np.mean(expit(inv_temp * (p - threshold)))\n",
    "\n",
    "            loss -= q.log_prob(trajectory).sum().exp() * learning_reward\n",
    "\n",
    "            for t in range(n_step):\n",
    "                q = dist.Categorical(logits_action[t])\n",
    "                loss += torch.distributions.kl_divergence(q, prior_action)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "        pbar.update()\n",
    "\n",
    "\n",
    "traj = np.argmax(logits_action.detach().numpy(), axis=1)\n",
    "\n",
    "n_pres = deepcopy(current_n_pres)\n",
    "delta = deepcopy(current_delta)\n",
    "\n",
    "for item in range(n_item):\n",
    "\n",
    "    item_pres = traj == item\n",
    "    n_pres_traj = np.sum(item_pres)\n",
    "    n_pres[item] += n_pres_traj\n",
    "    if n_pres_traj == 0:\n",
    "        delta[item] += np.sum(delays)\n",
    "    else:\n",
    "        idx_last_pres = np.arange(t_remaining)[item_pres][-1]\n",
    "        delta[item] = np.sum(delays[idx_last_pres:])\n",
    "\n",
    "p = np.zeros(n_item)\n",
    "\n",
    "view = n_pres > 0\n",
    "rep = n_pres[view] - 1.\n",
    "delta = delta[view]\n",
    "\n",
    "init_fr = initial_forget_rates[view]\n",
    "rep_eff = repetition_rates[view]\n",
    "\n",
    "forget_rate = init_fr * (1 - rep_eff) ** rep\n",
    "logp_recall = - forget_rate * delta\n",
    "\n",
    "p[n_pres > 0] = np.exp(logp_recall)\n",
    "\n",
    "learning_reward = np.mean(expit(inv_temp * (p - threshold)))\n",
    "\n",
    "print(traj)\n",
    "print(learning_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "079d6d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_traj = cartesian_product(*[np.arange(2) \n",
    "                               for _ in range(2)])\n",
    "all_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a9acceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2134)\n",
      "tensor(0.2134)\n"
     ]
    }
   ],
   "source": [
    "n_step, n_item = 5, 4\n",
    "logits_action = torch.rand((n_step, n_item))\n",
    "\n",
    "loss = 0\n",
    "p = dist.Categorical(logits=torch.ones(n_item))\n",
    "for t in range(n_step):\n",
    "    q = dist.Categorical(logits=logits_action[t])\n",
    "    loss += torch.distributions.kl_divergence(q, p)\n",
    "print(loss)\n",
    "\n",
    "loss = 0\n",
    "p = dist.Categorical(logits=torch.ones((n_step, n_item)))\n",
    "q = dist.Categorical(logits=logits_action)\n",
    "loss = torch.distributions.kl_divergence(q, p).sum()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d4412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2461b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
