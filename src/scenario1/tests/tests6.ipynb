{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95f53f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "belief_updt_n_epochs = 4\n",
    "belief_updt_lr = 0.1\n",
    "action_slc_n_epochs = 5\n",
    "action_slc_lr = 0.1\n",
    "n_target = 2\n",
    "mvt_amplitude = 3\n",
    "max_coord = torch.tensor([300., 600.])\n",
    "n_rollout = 3\n",
    "n_step_per_rollout = 3\n",
    "user_sigma = 5\n",
    "decay_factor = 0.9\n",
    "\n",
    "x = torch.tensor([[0.25, 0.25], [0.75, 0.75]]) * max_coord\n",
    "b = torch.ones(n_target) / n_target\n",
    "\n",
    "a = torch.nn.Parameter(torch.zeros(n_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218ccd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_environment(positions, action):\n",
    "    \n",
    "    for i in range(n_target):\n",
    "        angle = action[i]\n",
    "        if 90 < angle <= 270:\n",
    "            x_prime = -1\n",
    "        else:\n",
    "            x_prime = 1\n",
    "        y_prime = torch.tan(torch.deg2rad(angle)) * x_prime\n",
    "\n",
    "        norm = mvt_amplitude / torch.sqrt(y_prime**2 + x_prime**2)\n",
    "        movement = torch.tensor([x_prime, y_prime]) * norm\n",
    "        positions[i] += movement\n",
    "\n",
    "    for coord in range(2):\n",
    "        for target in range(n_target):\n",
    "            if positions[target, coord] > max_coord[coord]:\n",
    "                positions[target, coord] = max_coord[coord]\n",
    "                \n",
    "    return positions\n",
    "                \n",
    "\n",
    "def logp_action(positions, action, prev_positions):\n",
    "    \n",
    "    logp_y = torch.zeros(n_target)\n",
    "    for target in range(n_target):\n",
    "        for coord in range(2):\n",
    "            d = positions[target, coord] - prev_positions[target, coord]\n",
    "            logp_coord = torch.distributions.Normal(d, user_sigma).log_prob(action[coord])\n",
    "            logp_y[target] += logp_coord\n",
    "            \n",
    "    return logp_y\n",
    "\n",
    "\n",
    "def sim_act(positions, prev_positions, goal):\n",
    "    \n",
    "    delta = positions[goal] - prev_positions[goal]\n",
    "    noise = torch.randn(2) * user_sigma\n",
    "    y = delta + noise\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "a = torch.nn.Parameter(a)\n",
    "a_opt = torch.optim.Adam([a, ], lr=0.01)\n",
    "\n",
    "for _ in range(213):\n",
    "\n",
    "    old_a = a.clone()\n",
    "    a_opt.zero_grad()\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Build action plans\n",
    "    # -----------------------------------\n",
    "\n",
    "    first_action = torch.sigmoid(a)\n",
    "\n",
    "    action_plan = torch.zeros((n_rollout, n_step_per_rollout, n_target))\n",
    "    action_plan[:, 0] = first_action\n",
    "    if n_step_per_rollout > 1:\n",
    "        action_plan[:, 1:, :] = torch.rand((n_rollout, n_step_per_rollout - 1, n_target)) * 360\n",
    "\n",
    "    action_plan *= 360  # Convert in degrees\n",
    "\n",
    "    total_efe = 0\n",
    "    for rol in range(n_rollout):\n",
    "\n",
    "        efe_rollout = 0\n",
    "\n",
    "        # Sample the user goal --------------------------\n",
    "\n",
    "        q = torch.softmax(b - b.max(), dim=0)\n",
    "        goal = torch.multinomial(q, 1)[0]\n",
    "\n",
    "        # -----------------------------------------------\n",
    "\n",
    "        x_rol = x.clone()\n",
    "        b_rol = b.clone()\n",
    "\n",
    "        for step in range(n_step_per_rollout):\n",
    "\n",
    "            action = action_plan[rol, step]\n",
    "\n",
    "            # ---- Update positions based on action ---------------------------------------------\n",
    "\n",
    "            x_rol_prev = x_rol.clone()\n",
    "\n",
    "            x_rol = update_environment(positions=x_rol, action=action)\n",
    "\n",
    "            # ------------------------------------------------------------------------------\n",
    "            # Evaluate epistemic value -----------------------------------------------------\n",
    "            # ------------------------------------------------------------------------------\n",
    "\n",
    "            # Simulate action based on goal ----------------------------------------\n",
    "\n",
    "            y = sim_act(positions=x_rol, goal=goal, prev_positions=x_rol_prev)\n",
    "\n",
    "            # Compute log probability of user action given a specific goal in mind -------\n",
    "            logp_y = logp_action(positions=x_rol, action=y, prev_positions=x_rol_prev)\n",
    "\n",
    "            logq = torch.log_softmax(b_rol - b_rol.detach().max(), dim=0)\n",
    "            logp_yq = logq + logp_y\n",
    "\n",
    "            # Revise belief -------------------\n",
    "\n",
    "            b_rol = torch.nn.Parameter(b_rol)\n",
    "            b_opt = torch.optim.Adam([b_rol, ], lr=0.01)\n",
    "\n",
    "            q_rol, kl_div = None, None\n",
    "\n",
    "            for _ in range(132):\n",
    "\n",
    "                old_b = b_rol.clone()\n",
    "                b_opt.zero_grad()\n",
    "                q_rol = torch.softmax(b_rol - b_rol.detach().max(), dim=0)\n",
    "                kl_div = torch.sum(q_rol * (q_rol.log() - logp_yq))\n",
    "                kl_div.backward(retain_graph=True)\n",
    "                b_opt.step()\n",
    "\n",
    "                if torch.isclose(old_b, b_rol).all():\n",
    "                    break\n",
    "\n",
    "            epistemic_value = kl_div\n",
    "\n",
    "            # --------------------------------------\n",
    "            # Compute extrinsic value\n",
    "            # --------------------------------------\n",
    "\n",
    "            extrinsic_value = (q_rol * q_rol.log()).sum()  # minus entropy\n",
    "\n",
    "            # --------------------------------------\n",
    "            # Compute loss\n",
    "            # ---------------------------------------\n",
    "            efe_step = - epistemic_value - extrinsic_value\n",
    "            efe_rollout += decay_factor ** step * efe_step\n",
    "\n",
    "        total_efe += efe_rollout\n",
    "\n",
    "    total_efe /= n_rollout\n",
    "    total_efe.backward()\n",
    "    a_opt.step()\n",
    "\n",
    "    if torch.isclose(old_a, a).all():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d760383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
